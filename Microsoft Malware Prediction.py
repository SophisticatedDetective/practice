import numpy as np
import pandas as pd
import lightgbm as lgb
import xgboost as xgb
from sklearn import *

train = pd.read_csv('../input/train.csv', iterator=True, chunksize=500000)
test = pd.read_csv('../input/test.csv', iterator=True, chunksize=500000)
gf_defaults = {'col': [], 'ocol':[], 'dcol' : ['EngineVersion', 'AppVersion', 'AvSigVersion', 'OsBuildLab', 'Census_OSVersion']}
one_hot = {}

def get_features(df, gf_train=True):
    global one_hot
    global gf_defaults
    
    for c in gf_defaults['dcol']:
        for i in range(5):
            df[c + str(i)] = df[c].map(lambda x: str(x).split('.')[i] if len(str(x).split('.'))>i else -1)

    col = [c for c in df.columns if c not in ['MachineIdentifier', 'HasDetections']]
    for c in col:
            if df[c].dtype == 'O' or df[c].dtype.name == 'category':
                gf_defaults['ocol'].append(c)
            else:
                gf_defaults['col'].append(c)
    one_hot = {c: list(df[c].value_counts().index) for c in gf_defaults['ocol']}
    for c in one_hot:
        if len(one_hot[c])>1 and len(one_hot[c]) < 20:
            for val in one_hot[c]:
                df[c+'_oh_' + str(val)] = (df[c].values == val).astype(np.int)
                gf_defaults['col'].append(c+'_oh_' + str(val))
    return df[gf_defaults['col']+['MachineIdentifier', 'HasDetections']]
col = gf_defaults['col']
model = []
params = {'objective':'binary', "boosting": "gbdt", 'learning_rate': 0.01, 'max_depth': -1, 
         "feature_fraction": 0.8, "bagging_freq": 1, "bagging_fraction": 0.8 , "bagging_seed": 1,
         "metric": 'auc', "lambda_l1": 0.1, 'num_leaves': 50, 'min_data_in_leaf': 50, "verbosity": -1, "random_state": 0}

for df in train:
    
        df = get_features(df, True)
        x1, x2, y1, y2 = model_selection.train_test_split(df[col], df['HasDetections'], test_size=0.3, random_state=0)
        model = lgb.train(params, lgb.Dataset(x1, y1), 2500,  lgb.Dataset(x2, y2), verbose_eval=100, early_stopping_rounds=200)
        model.save_model('lgb.model')
predictions = []
for df in test:
    df['HasDetections'] = 0.0
    df = get_features(df)
    df['HasDetections'] = model.predict(df[col], num_iteration=model.best_iteration + 100)
    predictions.append(df[['MachineIdentifier', 'HasDetections']].values)
    print('testing...')
sub = np.concatenate(predictions)
sub = pd.DataFrame(sub, columns = ['MachineIdentifier', 'HasDetections'])
sub.to_csv('submission.csv', index=False)
